{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect people loitering \n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vqpy/vqpy/blob/main/examples/loitering/demo.ipynb)\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Loitering is the activity of remaining in an area for no obvious reason.\n",
    "\n",
    "In the example [video](https://youtu.be/EuLMrUFNRxQ), we consider the region inside the garage private, and tries to detect people staying within that region for a prolonged time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install VQPy\n",
    "\n",
    "\tPython3.8 is recommended to avoid compatibility issues when installing YOLOX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision numpy==1.23.5 cython\n",
    "%pip install 'vqpy @ git+https://github.com/vqpy/vqpy.git'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might need to restart Jupyter Notebook runtime in order to use newly installed versions of `numpy`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Download video from [here](https://youtu.be/EuLMrUFNRxQ) and place it in the same directory as this notebook.\n",
    "\n",
    "3. Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./loitering.mp4\"\t# or change to where you put the video\n",
    "save_folder = \"./vqpy_outputs\"\t# folder to save query results, will be created later if does not exist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the working directory should look like:\n",
    "```text\n",
    ".\n",
    "├── loitering.mp4\t# video to query on\n",
    "└── vqpy\t# VQPy repo\n",
    "    └── vqpy\t# VQPy library\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People loitering query with VQPy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define a `Person` `VObj`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in people, first define a `Person` class. In this example, we will only be using the coordinates of each person, which are all built-in to VObj, so no extra property needs to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vqpy\n",
    "class Person(vqpy.VObjBase):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the defined VObj type, we can filter all VObjs that's identified to be a person with:\n",
    "\n",
    "```python\n",
    "\"__class__\": lambda x: x == Person\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define people loitering query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify filtering conditions on `VObj` (`filter_cons`)\n",
    "\n",
    "Trying to find people that stays in the region of interest, we filter on the coordinate of a person's base of support. This can be approximated to a built-in property of VObj: `bottom_center`, the point located at the center of the lower edge of VObj's bounding box.\n",
    "\n",
    "Knowing where the person is, the next step is to determine if the coordinate is within the region of interest (i.e. the garage), marked by the red polygon shown below.\n",
    "\n",
    "<img src=\"./demo.assets/region.png\" alt=\"region of interest\" style=\"zoom: 30%;\" />\n",
    "\n",
    "`vqpy.query.utils.within_regions([REGION, ...])` accepts a coordinate and returns `True` if it's in any of the `REGION`s.\n",
    "\n",
    "The polygon is outlined by its 5 vertices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = [(550, 550), (1162, 400), (1720, 720), (1430, 1072), (600, 1073)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicate to filter VObjs in the region is then:\n",
    "\n",
    "```python\n",
    "\"bottom_center\": vqpy.query.utils.within_regions([REGION])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we wish to find person staying in the region for some duration, `vqpy.query.continuing` could wrap the above predicate and specify the minimum time it should be satisfied.\n",
    "\n",
    "`duration=10` sets the time threshold to 10 seconds; `name=\"in_roi\"` can be used later to retrieve time periods of condition being satisfied.\n",
    "\n",
    "Predicate used to filter on `bottom_center` becomes:\n",
    "\n",
    "```python\n",
    "\"bottom_center\": vqpy.query.continuing(\n",
    "    condition=vqpy.query.utils.within_regions([REGION]),\n",
    "    duration=10, name=\"in_roi\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining everything we have so far, the filter condition of the query should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_cons = {\n",
    "    \"__class__\": lambda x: x == Person,\n",
    "    \"bottom_center\": vqpy.query.continuing(\n",
    "        condition=vqpy.query.utils.within_regions([REGION]), duration=10, name=\"in_roi\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select `VObj`'s properties for output (`select_cons`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each VObj that satisfies the filter conditions, we can select its properties to output. The selection is done by specifying a property name as key in the dictionary `select_cons`, where the name is either a property defined in VObj or a property from vqpy's built-in property library. The values of the dictionary are optional post-processing functions applied to value of the properties before serializing the results.\n",
    "\n",
    "In this example, we select:\n",
    "\n",
    "- `track_id`, tracking id, a built-in property of VObj\n",
    "- `coordinate`, center coordinate of the VObj, from vqpy's built-in property library. Since the value of `coordinate` is of type `numpy.ndarray`, we need to convert it to a string with the lambda function before serializing it.\n",
    "\n",
    "\tIt makes more sense to use the center of the bounding box for outputs (while `bottom_center` is the point located at center of the lower lower edge of VObj's bounding box, an approximation of where a person is standing).\n",
    "\n",
    "- `in_roi_periods`, a list of time periods (in seconds) of VObjs satisfying the condition.\n",
    "\n",
    "\tThis property is added to `Person` by wrapper `vqpy.query.continuing`, and the name comes from appending `\"_periods\"` to the `name` defined in `vqpy.query.continuing`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The select condition of the query could be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cons = {\n",
    "    \"track_id\": None,\n",
    "    \"coordinate\": lambda x: str(x),  # convert to string for JSON serialization\n",
    "    # name in vqpy.query.continuing + '_periods' can be used in select_cons.\n",
    "    \"in_roi_periods\": None,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct the query with `filter_cons` and `select_cons`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheriting `vqpy.QueryBase`, we can compose a query using the `filter_cons` and `select_cons` created earlier. `filename` will be used in name of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class People_loitering_query(vqpy.QueryBase):\n",
    "    @staticmethod\n",
    "    def setting() -> vqpy.VObjConstraint:\n",
    "        return vqpy.VObjConstraint(\n",
    "            filter_cons, select_cons, filename=\"loitering\"\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Running the query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `Person` VObj and the query defined, we can run the query, where:\n",
    "\n",
    "- `cls_name` is a tuple for mapping numerical outputs of object detector to str\n",
    "\n",
    "\t`COCO_CLASSES` can be used here since it includes all the class names of interest in the fall detection query, i.e. `\"person\"`.\n",
    "\n",
    "- dictionary `cls_type` is then used to map detection class name (in str) to VObj types defined\n",
    "\n",
    "\t`{\"person\": Person}` means we wish to map COCO class `person` to VObj type `Person`\n",
    "\n",
    "- `tasks` is a list of queries to run on the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqpy.launch(\n",
    "        cls_name=vqpy.COCO_CLASSES,\n",
    "        cls_type={\"person\": Person},\n",
    "        tasks=[People_loitering_query()],\n",
    "        video_path=video_path,\n",
    "        save_folder=save_folder,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of the query will be in `{save_folder}/{video_name}_{task_name}_{detector_name}.json`, output for this example should be in `./vqpy_outputs/loitering_loitering_yolox.json`.\n",
    "\n",
    "One entry is created for each frame that has filter condition satisfied.\n",
    "\n",
    "The 765th frame as an example:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"frame_id\": 765,\n",
    "    \"data\": [\n",
    "      {\n",
    "        \"track_id\": 606,\n",
    "        \"coordinate\": \"[1426.5312   492.42188]\",\n",
    "        \"in_roi_periods\": [[40, 50]]\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Marking person's `coordinate` with a red circle, this is\n",
    "\n",
    "<img src=\"./demo.assets/marked.png\" alt=\"with coordinate marked\" style=\"zoom: 30%;\" />\n",
    "\n",
    "Value of `in_roi_periods` indicates that the person has been in the region in time period 00:40-00:50."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
